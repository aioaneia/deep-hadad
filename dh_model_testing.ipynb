{"cells":[{"cell_type":"markdown","metadata":{"id":"rUiPvRyhgbXt"},"source":["### Image To Image Translation Model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10369,"status":"ok","timestamp":1702710510283,"user":{"displayName":"Andrei Aioanei","userId":"01501721901742656014"},"user_tz":-60},"id":"WrJhF-f_iqLb"},"outputs":[],"source":["import matplotlib.pyplot  as plt\n","import torch\n","\n","from torchvision import transforms\n","from PIL         import Image"]},{"cell_type":"markdown","metadata":{"id":"7jlwr5DkWWdc"},"source":["### Project path in Google Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19297,"status":"ok","timestamp":1702710532378,"user":{"displayName":"Andrei Aioanei","userId":"01501721901742656014"},"user_tz":-60},"id":"XLftWlQ5WWdh","outputId":"0edaa8d2-25f8-4484-e2d1-5cdae437452b"},"outputs":[],"source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","# Set the project path in the drive\n","PROJECT_PATH = '/content/drive/My Drive/Research Hub/Projects/Present Projects/{Deep Hadad}/Implementation/DeepHadadProject/'"]},{"cell_type":"markdown","metadata":{"id":"_GhGemFFWWdh"},"source":["### Local Project path"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Mh4hnQo1WWdh"},"outputs":[],"source":["PROJECT_PATH = './'"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4098,"status":"ok","timestamp":1702710538830,"user":{"displayName":"Andrei Aioanei","userId":"01501721901742656014"},"user_tz":-60},"id":"BTW6k6XPuvRC"},"outputs":[],"source":["import sys\n","sys.path.append(PROJECT_PATH)\n","\n","import core.networks as dh_networks"]},{"cell_type":"markdown","metadata":{"id":"uzYgg8BBWWdh"},"source":["### Constants"]},{"cell_type":"code","execution_count":81,"metadata":{"executionInfo":{"elapsed":411,"status":"ok","timestamp":1702710541796,"user":{"displayName":"Andrei Aioanei","userId":"01501721901742656014"},"user_tz":-60},"id":"mxtAsVhGWWdi"},"outputs":[],"source":["MODEL_PATH        = PROJECT_PATH + 'models/'\n","\n","# Model name\n","MODEL_NAME = 'dh_model_e_0_.pth'\n","\n","# Load and transform the broken image\n","#test_image_path = PROJECT_PATH + \"data/test_dataset/X/KAI_214_x_d_m_2.png\"\n","test_image_path = PROJECT_PATH + \"data/test_dataset/X/d_m_test_5.png\"\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"Eb1yDU3lCQyr"},"source":["### Generating a restored image from a broken one"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vgS39F4vCd6V"},"outputs":[],"source":["\n","gen_in_channels  = 1  # grayscale images, 3 for RGB images\n","gen_out_channels = 1  # to generate grayscale restored images, change as needed\n","\n","# Instantiate the generator with the specified channel configurations\n","generator = dh_networks.DHadadGenerator(gen_in_channels, gen_out_channels).to(device)\n","\n","# Load the pre-trained weights\n","checkpoint = torch.load(MODEL_PATH + MODEL_NAME, map_location=device)\n","\n","# Load the pre-trained weights\n","generator.load_state_dict(checkpoint)\n","\n","# Set the model to evaluation mode\n","generator.eval()\n","\n","transform = transforms.Compose([\n","  transforms.Resize((512, 512)),\n","  transforms.Lambda(lambda x: x.convert('L')),\n","  transforms.ToTensor(),\n","])\n","\n","# Load the image\n","test_image_pil = Image.open(test_image_path)\n","\n","# Transform the image\n","test_image_tensor = transform(test_image_pil).to(device)\n","\n","# Turn off gradients for testing\n","with torch.no_grad():\n","    # Add a batch dimension and move to the GPU if needed\n","    broken_image = test_image_tensor.unsqueeze(0).to(device)\n","\n","    # Generate the restored image and remove the batch dimension\n","    restored_image = generator(broken_image).squeeze(0).cpu()\n","\n","# Invert the pixel values\n","restored_image = restored_image\n","\n","# Normalize the image to the range [0, 1]\n","#restored_image = (restored_image - restored_image.min()) / (restored_image.max() - restored_image.min())\n","\n","# Convert the tensor to a PIL Image and show/save it\n","restored_image_pil = transforms.ToPILImage()(restored_image)\n","\n","fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n","\n","# Show original image\n","axes[0].imshow(test_image_pil, cmap='gray')\n","axes[0].set_title('Original Image')\n","axes[0].axis('off')\n","\n","# Show restored image\n","axes[1].imshow(restored_image_pil, cmap='gray')\n","axes[1].set_title('Restored Image')\n","axes[1].axis('off')\n","\n","plt.show()\n","\n","restored_image_pil.save(PROJECT_PATH + \"data/test_dataset/R_image.png\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}
