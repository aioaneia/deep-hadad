{"cells":[{"cell_type":"markdown","metadata":{"id":"rUiPvRyhgbXt"},"source":["### Image To Image Translation Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GHpkMFd1uGFf"},"outputs":[],"source":["!pip install lpips\n","!pip install pytorch_msssim"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WrJhF-f_iqLb"},"outputs":[],"source":["import os\n","import time\n","import numpy as np\n","import pandas as pd\n","import logging\n","\n","import matplotlib.pyplot  as plt\n","\n","from lpips import LPIPS\n","\n","import torch\n","import torch.nn            as nn\n","import torch.nn.functional as F\n","\n","from torch.nn.utils           import clip_grad_norm_\n","from torch.utils.data         import Dataset, DataLoader, TensorDataset\n","from torch.utils.tensorboard  import SummaryWriter\n","from torch.optim              import Adam\n","from torch.optim.lr_scheduler import StepLR\n","from torch.cuda.amp import GradScaler\n","\n","from torchvision            import transforms\n","from torchvision.transforms import Grayscale\n","\n","from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n","\n","from PIL import Image\n","\n","from sklearn.model_selection import train_test_split\n","from skimage.morphology import disk\n","from math import log10\n","\n","logging.getLogger('lpips').setLevel(logging.WARNING)"]},{"cell_type":"markdown","metadata":{"id":"7jlwr5DkWWdc"},"source":["Project path in Google Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3702,"status":"ok","timestamp":1701800916139,"user":{"displayName":"Andrei Aioanei","userId":"01501721901742656014"},"user_tz":-60},"id":"XLftWlQ5WWdh","outputId":"b5aa3150-adc0-491c-d826-42686ef451cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","PROJECT_PATH = '/content/drive/My Drive/Research Hub/Projects/Present Projects/{Deep Hadad}/Implementation/DeepHadadProject/'"]},{"cell_type":"markdown","metadata":{"id":"_GhGemFFWWdh"},"source":["Local Project path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mh4hnQo1WWdh"},"outputs":[],"source":["PROJECT_PATH = './'"]},{"cell_type":"markdown","metadata":{"id":"uzYgg8BBWWdh"},"source":["### Constants"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mxtAsVhGWWdi"},"outputs":[],"source":["TEST_DATASET_PATH       = PROJECT_PATH + 'data/real_images'\n","TRAINING_DATASET_PATH   = PROJECT_PATH + 'data/training_dataset'\n","X_TRAINING_DATASET_PATH = TRAINING_DATASET_PATH + '/X'\n","Y_TRAINING_DATASET_PATH = TRAINING_DATASET_PATH + '/Y'\n","MODEL_PATH              = PROJECT_PATH + 'models/'\n","MODEL_NAME              = 'generator_model_v1.pth'\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","writer = SummaryWriter(PROJECT_PATH + '/runs/experiment_1')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BTW6k6XPuvRC"},"outputs":[],"source":["import sys\n","sys.path.append(PROJECT_PATH)\n","\n","import core.networks as dh_networks"]},{"cell_type":"markdown","metadata":{"id":"Bm-LULpeJOEG"},"source":["### Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tyGCgjU8JO1L"},"outputs":[],"source":["generator_lr     = 5e-5      # Reduced learning rate for generator\n","discriminator_lr  = 5e-5      # Unchanged learning rate for discriminator\n","batch_size      = 16\n","num_epochs    = 100"]},{"cell_type":"markdown","metadata":{"id":"37q6KY6IV88y"},"source":["### Dataset Loading"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":174919,"status":"ok","timestamp":1701801098296,"user":{"displayName":"Andrei Aioanei","userId":"01501721901742656014"},"user_tz":-60},"id":"CrlOJ6v8V7fV","outputId":"8af47f81-b4b4-4075-f8ff-3963f905ead0"},"outputs":[],"source":["IMAGE_EXTENSIONS = [\".png\", \".jpg\", \".jpeg\", \".tif'\", \".tiff\", \".bmp\"]\n","\n","# Function to get image from paths\n","def get_image_paths(directory):\n","    return [\n","        os.path.join(directory, fname)\n","\n","        for fname in sorted(os.listdir(directory))\n","        \n","        if os.path.splitext(fname)[1].lower() in IMAGE_EXTENSIONS\n","    ]\n","\n","# Get images from path\n","intact_image_paths    = get_image_paths(X_TRAINING_DATASET_PATH)\n","damaged_image_paths = get_image_paths(Y_TRAINING_DATASET_PATH)\n","\n","print(f\"Number of Paired Inscriptions: {len(intact_image_paths)}\")\n","print(f\"Number of Paired Inscriptions: {len(damaged_image_paths)}\")\n","\n","assert len(intact_image_paths) == len(damaged_image_paths), \"Number of intact and damaged images must be the same\"\n","\n","print(f\"Number of Paired Inscriptions: {len(intact_image_paths)}\")\n","\n","class DisplacementMapDataset(Dataset):\n","  def __init__(self, intact_image_paths, damaged_image_paths, transform=None):\n","    self.intact_image_paths  = intact_image_paths\n","    self.damaged_image_paths = damaged_image_paths\n","    self.transform           = transform\n","    self.counter             = 0\n","\n","  def __len__(self):\n","    return len(self.intact_image_paths)\n","\n","  def __getitem__(self, idx):\n","    while True:\n","      try:\n","        intact_image_path  = self.intact_image_paths[idx]\n","        damaged_image_path = self.damaged_image_paths[idx]\n","\n","        intact_image  = Image.open(intact_image_path)\n","        damaged_image = Image.open(damaged_image_path)\n","\n","        if self.transform:\n","          intact_image  = self.transform(intact_image)\n","          damaged_image = self.transform(damaged_image)\n","\n","        # Increment the counter and log every 100 pairs\n","        self.counter += 1\n","\n","        if self.counter % 100 == 0:\n","          print(f\"Processed {self.counter} pairs. Current pair: {intact_image_path}, {damaged_image_path}\")\n","\n","        return intact_image, damaged_image\n","      except IOError as e:\n","        print(f\"Error opening image files: {intact_image_path}, {damaged_image_path}. Error: {e}\")\n","        # Increment the index and try the next pair of images\n","        idx = (idx + 1) % len(self.intact_image_paths)\n","\n","# Common Data Augmentation\n","common_transforms = transforms.Compose([\n","  transforms.Resize((512, 512)),\n","  transforms.Lambda(lambda x: x.convert('L')),\n","  transforms.ToTensor()\n","])\n","\n","\n","# Calculate mean and std for the dataset\n","mean = 0.\n","std = 0.\n","\n","# Use a subset to calculate mean and std for efficiency\n","subset_intact_image_paths = intact_image_paths[:100]\n","subset_damaged_image_paths = damaged_image_paths[:100]\n","\n","for images, _ in DataLoader(DisplacementMapDataset(subset_intact_image_paths, subset_damaged_image_paths, transform=common_transforms), batch_size=batch_size):\n","    images       = images.to(device)  # Move images to GPU\n","    batch_samples = len(images)  # Use len() to get the number of images in the batch\n","    images       = images.view(batch_samples, images.size(1), -1)\n","    mean      += images.mean(2).sum(0)\n","    std        += images.std(2).sum(0)\n","\n","mean /= len(intact_image_paths)\n","std   /= len(intact_image_paths)\n","\n","# Now mean and std should be tensors of size 1\n","print(mean.size())  # Should print torch.Size([1])\n","print(std.size())  # Should print torch.Size([1])\n","\n","# Data Augmentation for the Real Images\n","image_transforms = transforms.Compose([\n","    transforms.RandomResizedCrop(512, scale=(0.8, 1.0)),\n","    transforms.RandomRotation(10),\n","    #transforms.RandomCrop(224),\n","    common_transforms,\n","    transforms.Normalize(mean=mean.tolist(), std=std.tolist())  # Scale pixels to the range [-1, 1]\n","])\n","\n","# Split the data into training and validation sets\n","train_intact, val_intact, train_damaged, val_damaged = train_test_split(\n","    intact_image_paths, damaged_image_paths, test_size=0.2, random_state=42)\n","\n","# Create training and validation datasets and dataloaders\n","train_dataset = DisplacementMapDataset(train_intact, train_damaged, transform = image_transforms)\n","val_dataset   = DisplacementMapDataset(val_intact, val_damaged, transform = image_transforms)\n","\n","# Create dataset and dataloader\n","train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n","val_dataloader   = DataLoader(val_dataset, batch_size = batch_size, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"6gVYSuc_C43V"},"source":["### MODEL INITIALIZATION"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"80xJHGQoC3Ds"},"outputs":[],"source":["gen_in_channels  = 1  # grayscale images, 3 for RGB images\n","gen_out_channels = 1  # to generate grayscale restored images, change as needed\n","\n","# Instantiate the generator with the specified channel configurations\n","generator = dh_networks.DHadadGenerator(gen_in_channels, gen_out_channels).to(device)\n","\n","# Specify the input channel configurations (for the discriminator, it typically takes two inputs)\n","# Assuming you're providing pairs of images (intact and restored) as input\n","# and not input channels set to 3 (concatenation of real and synthetic images plus condition)\n","disc_in_channels = 1\n","\n","discriminator = dh_networks.DHadadDiscriminator(disc_in_channels).to(device)"]},{"cell_type":"markdown","metadata":{"id":"PAp0jCJVnQye"},"source":["### Initialize loss functions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4817,"status":"ok","timestamp":1701801119702,"user":{"displayName":"Andrei Aioanei","userId":"01501721901742656014"},"user_tz":-60},"id":"yJyTNQoxna3W","outputId":"db330f16-735b-4aa8-fb05-47fe0ccef084"},"outputs":[],"source":["########################################################################################\n","# Mean Squared Error(MSE) Loss\n","# It ensures the overall structure of the reconstructed image\n","# is similar to the intact image.\n","# MSE could encourage blurred details, which can be detrimental for text recovery and for sharp engravings.\n","########################################################################################\n","mean_sq_error_loss = nn.MSELoss().to(device)\n","\n","########################################################################################\n","# L1 Loss\n","# It helps in recovering finer details without overly penalizing slight deviations that aren't perceptually significant.\n","########################################################################################\n","l1_loss = nn.L1Loss().to(device)\n","\n","########################################################################################\n","# Perceptual Loss\n","# Captures textural and stylistic features.\n","# luminance, and contrast in an image.\n","# A higher weight is crucial as it emphasizes on the perceptual similarity, which is key for letter reconstruction.\n","########################################################################################\n","class WeightedSSIMLoss(nn.Module):\n","    def __init__(self, data_range=255, size_average=True, channel=1, weight=1.0):\n","        super(WeightedSSIMLoss, self).__init__()\n","        self.ssim = SSIM(data_range=data_range, size_average=size_average, channel=channel)\n","        self.weight = weight\n","\n","    def forward(self, img1, img2):\n","        ssim_loss = self.ssim(img1, img2)\n","        weighted_ssim_loss = self.weight * (1 - ssim_loss)  # Weighted SSIM loss\n","\n","        return weighted_ssim_loss\n","\n","weighted_ssim_loss = WeightedSSIMLoss(data_range=255, size_average=True, channel=1, weight=1.0)\n","\n","########################################################################################\n","# LPIPS Loss\n","# LPIPS is a perceptual loss that uses a pretrained VGG19 network to calculate\n","########################################################################################\n","lpips_loss = LPIPS(net='vgg').to(device)  # Use the AlexNet layer\n","\n","########################################################################################\n","# Adversarial Loss\n","# TO encourage the generator to create images that are indistinguishable\n","# from the intact displacement maps.\n","# Encourages realism in the generated maps.\n","# Keeping this weight lower ensures that the focus remains on structural and textural accuracy rather than just realism.\n","########################################################################################\n","bce_with_logits_loss = nn.BCEWithLogitsLoss().to(device)\n","\n","def adversarial_loss(discriminator_preds, is_real=True):\n","    if is_real:\n","        labels = torch.ones_like(discriminator_preds).to(device)\n","    else:\n","        labels = torch.zeros_like(discriminator_preds).to(device)\n","\n","    return bce_with_logits_loss(discriminator_preds, labels)\n","\n","########################################################################################\n","# DepthConsistencyLoss\n","# This is a robust loss that combines the benefits of L1 and L2 losses.\n","# It can be particularly useful if there's a lot of noise in the damaged maps.\n","# Depth data is uncertain in some places\n","# This loss can help in smoothing the depth map without losing essential details.\n","########################################################################################\n","class DepthConsistencyLoss(nn.Module):\n","    def __init__(self, epsilon=1e-6):\n","        super(DepthConsistencyLoss, self).__init__()\n","        self.epsilon = epsilon\n","\n","    def forward(self, generated_depth, target_depth):\n","        # Assuming generated_depth and target_depth are tensors representing depth maps\n","        # Charbonnier Loss: sqrt((x - y)^2 + epsilon)\n","        loss = torch.mean(torch.sqrt((generated_depth - target_depth) ** 2 + self.epsilon))\n","        return loss\n","\n","depth_consistency_loss = DepthConsistencyLoss().to(device)\n","\n","########################################################################################\n","# Geometric Consistency Loss\n","# Maintains geometric integrity of depth information.\n","# This will help in preserving the contours and shapes of letters in the displacement maps.\n","########################################################################################\n","class GeometricConsistencyLoss(nn.Module):\n","    def __init__(self):\n","        super(GeometricConsistencyLoss, self).__init__()\n","\n","    def forward(self, predicted_map, target_map):\n","        # Calculate gradients in x and y direction\n","        # These gradients represent the change in depth (or displacement) across pixels\n","        grad_x_pred, grad_y_pred = self.compute_gradients(predicted_map)\n","        grad_x_target, grad_y_target = self.compute_gradients(target_map)\n","\n","        # Calculate the loss as the mean squared error between the gradients of the predicted and target maps\n","        loss_x = F.mse_loss(grad_x_pred, grad_x_target)\n","        loss_y = F.mse_loss(grad_y_pred, grad_y_target)\n","\n","        # Combine the losses\n","        loss = loss_x + loss_y\n","\n","        return loss\n","\n","    def compute_gradients(self, map):\n","        # Function to compute gradients in the x and y direction\n","        grad_x = map[:, :, :, :-1] - map[:, :, :, 1:]\n","        grad_y = map[:, :, :-1, :] - map[:, :, 1:, :]\n","\n","        return grad_x, grad_y\n","\n","# Example usage\n","geometric_consistency_loss = GeometricConsistencyLoss().to(device)\n","\n","\n","def tv_loss(img):\n","    batch_size, _, height, width = img.size()\n","    tv_h = torch.pow(img[:, :, 1:, :] - img[:, :, :-1, :], 2).sum()\n","    tv_w = torch.pow(img[:, :, :, 1:] - img[:, :, :, :-1], 2).sum()\n","\n","    return (tv_h + tv_w) / (batch_size * height * width)\n","\n","########################################################################################\n","# Dynamic Loss Weights\n","########################################################################################\n","class DynamicLossWeights:\n","    def __init__(self, initial_weights, max_weight=1.0, min_weight=0.01, decay_factor=0.9):\n","        self.weights = initial_weights\n","        self.max_weight = max_weight\n","        self.min_weight = min_weight\n","        self.decay_factor = decay_factor\n","\n","    def update_weights(self, performance_metrics):\n","        # Adjust weights based on the specific metric and its improvement\n","        for metric, info in performance_metrics.items():\n","            improvement = info['improved']\n","            magnitude = info['magnitude']\n","\n","            if metric == 'psnr':\n","                # PSNR is a measure of reconstruction quality.\n","                # Higher PSNR should potentially reduce the weight of perceptual losses\n","                # as structural integrity improves.\n","                self.adjust_weight_for_metric('gamma_ssim', not improvement, magnitude)\n","                self.adjust_weight_for_metric('gamma_lpips', not improvement, magnitude)\n","\n","                # If PSNR is improving, structural losses like MSE can be reduced\n","                self.adjust_weight_for_metric('alpha', improvement, magnitude)\n","\n","            if metric == 'ssim':\n","                # SSIM focuses on structural similarity.\n","                # Improvement in SSIM indicates better structural integrity.\n","                self.adjust_weight_for_metric('beta', not improvement, magnitude)  # L1 Loss adjustment\n","\n","                # Adversarial loss might be tuned down if SSIM is high, focusing more on realism\n","                self.adjust_weight_for_metric('delta', improvement, magnitude)\n","\n","        # Normalize weights after adjustment\n","        # self.normalize_weights()\n","\n","        return self.weights\n","\n","    def adjust_weight_for_metric(self, weight_key, improvement, magnitude):\n","        factor = self.decay_factor if improvement else 1.1 * (1 + magnitude)\n","\n","        self.weights[weight_key] *= factor\n","\n","        self.weights[weight_key] = min(max(self.weights[weight_key], self.min_weight), self.max_weight)\n","\n","    def normalize_weights(self):\n","        total_weight = sum(self.weights.values())\n","        for key in self.weights:\n","            self.weights[key] = (self.weights[key] / total_weight) * self.max_weight\n","\n","########################################################################################\n","# Initial Loss Weights\n","#\n","# Adjusting the loss weights for DeepHadad's displacement map inscription restoration\n","#\n","# * Alpha   (MSE loss)\n","# * Beta    (L1 reconstruction)\n","# * Gamma (Perceptual)\n","# * Delta   (Adversarial)\n","# * Epsilon (Charbonnier)\n","# * Zeta   (Geometric consistency)\n","#\n","########################################################################################\n","initial_weights = {\n","    'alpha':   0.2,     # Weight for MSE Loss\n","    'beta':    0.5,      # Weight for Reconstruction Loss (L1)\n","    'gamma_ssim': 0.3, # Weight for SSIM in Perceptual Loss\n","    'gamma_lpips': 0.1, # Weight for LPIPS in Perceptual Loss\n","    'delta':   0.05,       # Weight for Adversarial Loss\n","    'epsilon': 0.05,     # Weight for Depth Consistency Loss\n","    'zeta':    0.2,      # Weight for Geometric Consistency Loss\n","    'eta': 0.05         # Weight for TV Loss\n","}\n","\n","# initial_weights = {\n","#     'alpha': 0.1,      # Weight for MSE Loss\n","#     'beta': 0.4,       # Weight for Reconstruction Loss (L1)\n","#     'gamma_ssim': 0.2, # Weight for SSIM in Perceptual Loss\n","#     'gamma_lpips': 0.2, # Weight for LPIPS in Perceptual Loss\n","#     'delta': 0.05,     # Weight for Adversarial Loss\n","#     'epsilon': 0.05,   # Weight for Depth Consistency Loss\n","#     'zeta': 0.1,       # Weight for Geometric Consistency Loss\n","#     'eta': 0.01        # Weight for TV Loss\n","# }\n","\n","loss_weights    = DynamicLossWeights(initial_weights)\n","\n","########################################################################################\n","# Combined generator loss function.\n","########################################################################################\n","def combined_gen_loss(gen_imgs, real_imgs, discriminator_preds, loss_weights):\n","    # Mean Squared Error Loss\n","    mse_loss = mean_sq_error_loss(gen_imgs, real_imgs)\n","\n","    # Reconstruction Loss (L1)\n","    recon_loss = l1_loss(gen_imgs, real_imgs)\n","\n","    # Perceptual Loss\n","    ssim_loss      = weighted_ssim_loss(gen_imgs, real_imgs).to(device)\n","    lpips_loss_value = lpips_loss(gen_imgs, real_imgs)\n","\n","    perceptual_loss = loss_weights['gamma_ssim'] * ssim_loss + loss_weights['gamma_lpips'] * lpips_loss_value\n","\n","    # Adversarial Loss for the generator\n","    adv_loss = adversarial_loss(discriminator_preds, is_real=False)\n","\n","    # Charbonnier Loss (robust L1/L2 loss)\n","    depth_loss = depth_consistency_loss(gen_imgs, real_imgs)\n","\n","    # predicted_map and target_map are your generated and ground truth displacement maps, respectively\n","    geom_loss = geometric_consistency_loss(gen_imgs, real_imgs)\n","\n","    #TV loss function\n","    tv_loss_value = tv_loss(gen_imgs)\n","\n","\n","    combined_loss = torch.mean(\n","        loss_weights['alpha'] * mse_loss + \\\n","        loss_weights['beta'] * recon_loss + \\\n","        perceptual_loss +\n","        loss_weights['delta'] * adv_loss + \\\n","        loss_weights['epsilon'] * depth_loss + \\\n","        loss_weights['zeta'] * geom_loss + \\\n","        loss_weights['eta'] * tv_loss_value\n","    )\n","\n","    return combined_loss"]},{"cell_type":"markdown","metadata":{"id":"c0498ro7es0F"},"source":["### Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NiFoN2HbeqS0"},"outputs":[],"source":["# Define the maximum gradient norm for clipping\n","max_grad_norm = 1.0\n","\n","# Initialize optimizers\n","gen_optim = Adam(generator.parameters(), lr=generator_lr, betas=(0.5, 0.999))\n","dis_optim = Adam(discriminator.parameters(), lr=discriminator_lr, betas=(0.5, 0.999))\n","\n","#Learning Rate Scheduling\n","gen_scheduler = StepLR(gen_optim, step_size=30, gamma=0.1)\n","dis_scheduler = StepLR(dis_optim, step_size=30, gamma=0.1)\n","\n","# ----------------------------------------------------\n","# Define Evaluation Functions\n","# -------------------------------------------------\n","def compute_psnr(img1, img2):\n","    mse = F.mse_loss(img1, img2)\n","\n","    if mse == 0:\n","        return float('inf')\n","\n","    # Add a small positive number inside the square root to ensure the input is always non-negative\n","    return 20 * log10(1.0 / torch.sqrt(mse + 1e-10))\n","\n","def ssim(img1, img2, C1=0.01**2, C2=0.03**2):\n","    mu1 = torch.mean(img1, dim=[1, 2, 3])\n","    mu2 = torch.mean(img2, dim=[1, 2, 3])\n","\n","    sigma1_sq = torch.mean((img1 - mu1.reshape(-1, 1, 1, 1)) ** 2, dim=[1, 2, 3])\n","    sigma2_sq = torch.mean((img2 - mu2.reshape(-1, 1, 1, 1)) ** 2, dim=[1, 2, 3])\n","    sigma12   = torch.mean((img1 - mu1.reshape(-1, 1, 1, 1)) * (img2 - mu2.reshape(-1, 1, 1, 1)), dim=[1, 2, 3])\n","\n","    SSIM_n = (2 * mu1 * mu2 + C1) * (2 * sigma12 + C2)\n","    SSIM_d = (mu1 * mu1 + mu2 * mu2 + C1) * (sigma1_sq + sigma2_sq + C2)\n","    SSIM   = SSIM_n / SSIM_d\n","\n","    return torch.mean(SSIM)  # Return the mean SSIM over the batch\n","\n","\n","# ----------------------------------------------------\n","# Define Evaluation Functions\n","# Gradient Penalty\n","# The gradient penalty is typically used in the context of Wasserstein GANs\n","# with Gradient Penalty (WGAN-GP).\n","# It enforces the Lipschitz constraint by penalizing the gradient norm\n","# of the discriminator's output with respect to its input.\n","# -------------------------------------------------\n","def compute_gradient_penalty(D, real_samples, fake_samples):\n","    # Random weight term for interpolation between real and fake samples\n","    alpha = torch.rand((real_samples.size(0), 1, 1, 1), device=real_samples.device)\n","    # Get random interpolation between real and fake samples\n","    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n","    d_interpolates = D(interpolates)\n","    fake = torch.ones(d_interpolates.size(), requires_grad=False, device=real_samples.device)\n","\n","    # Get gradient w.r.t. interpolates\n","    gradients = torch.autograd.grad(\n","        outputs=d_interpolates,\n","        inputs=interpolates,\n","        grad_outputs=fake,\n","        create_graph=True,\n","        retain_graph=True,\n","        only_inputs=True,\n","    )[0]\n","\n","    gradients = gradients.view(gradients.size(0), -1)\n","    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n","    return gradient_penalty\n","\n","\n","# Initialize some variables for averaging\n","best_psnr = -float('inf')\n","best_ssim = -float('inf')\n","patience = 10  # Number of epochs to wait for improvement\n","epochs_no_improve = 0  # Counter for epochs without improvement\n","avg_psnr = 0.0\n","avg_ssim = 0.0\n","num_batches = 0\n","min_psnr, max_psnr = float('inf'), float('-inf')\n","min_ssim, max_ssim = float('inf'), float('-inf')\n","std_psnr, std_ssim = 0, 0  # Standard deviation\n","gen_loss, dis_loss = 0, 0  # Generator and Discriminator losse\n","psnrs, ssims = [], []  # Lists to store all PSNR and SSIM values for each epoch\n","epoch_times = []  # List to store time taken for each epoch\n","lambda_gp = 10  # The gradient penalty coefficient\n","\n","torch.autograd.set_detect_anomaly(True)\n","\n","# Initialize GradScaler\n","#scaler = GradScaler()\n","\n","# ----------------------------------------------------\n","# TRAINING LOOP\n","# ---------------------------------------------------\n","for epoch in range(num_epochs):\n","    # Start time for this epoch\n","    start_time = time.time()\n","    epoch_metrics = {'psnr': {'total': 0, 'count': 0}, 'ssim': {'total': 0, 'count': 0}}\n","\n","    for i, (intact, damaged) in enumerate(train_dataloader):\n","        intact, damaged = intact.to(device), damaged.to(device)\n","\n","        if epoch == 0 and i == 0:\n","            writer.add_graph(generator, damaged)\n","\n","        # Generate restored images from the damaged images\n","        restored = generator(damaged)\n","\n","        # ---------------------------------------------------\n","        # Update Discriminator\n","        # ---------------------------------------------------\n","        dis_optim.zero_grad()\n","\n","        output_real = discriminator(intact) # output_real = discriminator(intact, intact)\n","        output_fake = discriminator(restored.detach()) # output_fake = discriminator(damaged, restored.detach())\n","\n","        real_loss = adversarial_loss(output_real, is_real = True)\n","        fake_loss = adversarial_loss(output_fake, is_real = False)\n","\n","        gradient_penalty = compute_gradient_penalty(discriminator, intact, restored.detach())\n","\n","        dis_loss = (real_loss + fake_loss) / 2 + lambda_gp * gradient_penalty\n","\n","        # Scale the loss\n","        #scaled_dis_loss = scaler.scale(dis_loss)\n","        # Compute gradients for discriminator\n","        # scaled_dis_loss.backward()\n","        dis_loss.backward()\n","        dis_optim.step()\n","        # Optimize\n","        # scaler.step(dis_optim)\n","        # scaler.update()\n","        # Clip gradients for discriminator\n","        clip_grad_norm_(discriminator.parameters(), max_norm = max_grad_norm)\n","        # Reset gradients\n","        dis_optim.zero_grad()\n","\n","        # ---------------------------------------------------\n","        # Update Generator\n","        # ---------------------------------------------------\n","        gen_optim.zero_grad()\n","\n","        output_fake_for_gen = discriminator(restored) # output_fake_for_gen = discriminator(damaged, restored)\n","        gen_loss           = combined_gen_loss(restored, intact, output_fake_for_gen, loss_weights.weights)\n","\n","        # Scale the loss\n","        # scaled_gen_loss = scaler.scale(gen_loss)\n","        # Backprop\n","        # scaled_gen_loss.backward()\n","        gen_loss.backward()\n","        gen_optim.step()\n","        # Optimize\n","        # scaler.step(gen_optim)\n","        # scaler.update()\n","        # Clip gradients for generator\n","        clip_grad_norm_(generator.parameters(), max_norm=max_grad_norm)\n","        # Reset gradients\n","        gen_optim.zero_grad()\n","\n","\n","        # Step the learning rate scheduler\n","        gen_scheduler.step()\n","        dis_scheduler.step()\n","\n","        writer.add_scalar('Generator Loss',     gen_loss, global_step=epoch * len(train_dataloader) + i)\n","        writer.add_scalar('Discriminator Loss', dis_loss, global_step=epoch * len(train_dataloader) + i)\n","\n","    # ---------------------------------------------------\n","    # Validation step\n","    # ---------------------------------------------------\n","    with torch.no_grad():\n","          # Clip val gradients\n","        torch.nn.utils.clip_grad_norm_(generator.parameters(), max_norm=1.0)\n","\n","        for intact, damaged in val_dataloader:\n","            intact  = intact.to(device)\n","            damaged = damaged.to(device)\n","\n","            # Generate restored images\n","            restored = generator(damaged)\n","\n","            # Clamp the values to be between 0 and 1\n","            restored = restored.clamp(0, 1)\n","            intact = intact.clamp(0, 1)\n","\n","            writer.add_images('Restored Images', restored, global_step=epoch)\n","\n","            # Compute PSNR and SSIM for the current batch\n","            batch_psnr = compute_psnr(restored, intact)\n","            batch_ssim = ssim(restored, intact)\n","\n","            psnrs.append(batch_psnr)\n","            ssims.append(batch_ssim)\n","\n","            # Update epoch metrics\n","            epoch_metrics['psnr']['total'] += batch_psnr\n","            epoch_metrics['psnr']['count'] += 1\n","            epoch_metrics['ssim']['total'] += batch_ssim\n","            epoch_metrics['ssim']['count'] += 1\n","\n","    # Switch back to training mode\n","    generator.train()\n","    discriminator.train()\n","\n","    # Move tensors to CPU and convert to float\n","    psnrs_cpu = [x.cpu().item() if torch.is_tensor(x) else x for x in psnrs]\n","    ssims_cpu = [x.cpu().item() if torch.is_tensor(x) else x for x in ssims]\n","\n","    avg_psnr = np.mean(psnrs_cpu)\n","    avg_ssim = np.mean(ssims_cpu)\n","\n","    # At the end of the epoch, calculate average metrics\n","    avg_psnr_epoch = epoch_metrics['psnr']['total'] / epoch_metrics['psnr']['count']\n","    avg_ssim_epoch = epoch_metrics['ssim']['total'] / epoch_metrics['ssim']['count']\n","\n","    if avg_psnr > best_psnr:\n","      best_psnr = avg_psnr\n","      epochs_no_improve = 0\n","\n","      # Save the best model\n","      print(f\"Model saved at {epoch}\")\n","      torch.save(generator.state_dict(), MODEL_PATH + MODEL_NAME)\n","    else:\n","      epochs_no_improve += 1\n","\n","    # Inside the training loop, after calculating avg_ssim for the epoch\n","    if avg_ssim > best_ssim:\n","        best_ssim = avg_ssim\n","        ssim_improved = True\n","    else:\n","        ssim_improved = False\n","\n","    # Update loss weights based on performance\n","    performance_metrics = {\n","        'psnr': {'improved': avg_psnr_epoch > best_psnr, 'magnitude': abs(avg_psnr_epoch - best_psnr)},\n","        'ssim': {'improved': ssim_improved, 'magnitude': abs(avg_ssim_epoch - best_ssim)}\n","    }\n","\n","    loss_weights.update_weights(performance_metrics)\n","\n","    # Normalize weights every N epochs\n","    if epoch % 5 == 0:\n","      loss_weights.normalize_weights()\n","\n","    min_psnr, max_psnr = np.min(psnrs_cpu), np.max(psnrs_cpu)\n","    min_ssim, max_ssim = np.min(ssims_cpu), np.max(ssims_cpu)\n","    std_psnr, std_ssim = np.std(psnrs_cpu), np.std(psnrs_cpu)\n","\n","    # Calculate time taken for this epoch\n","    epoch_time = time.time() - start_time\n","    epoch_times.append(epoch_time)  # Store for future analysis if needed\n","\n","    # Logging\n","    print(f\"Epoch {epoch+1}/{num_epochs} - Time: {epoch_time:.2f}s\")\n","    print(f\"  Average PSNR: {avg_psnr:.4f} (Min: {min_psnr:.4f}, Max: {max_psnr:.4f}, Std: {std_psnr:.4f})\")\n","    print(f\"  Average SSIM: {avg_ssim:.4f} (Min: {min_ssim:.4f}, Max: {max_ssim:.4f}, Std: {std_ssim:.4f})\")\n","    print(f\"  Generator Loss: {gen_loss:.4f}, Discriminator Loss: {dis_loss:.4f}\")\n","\n","    writer.add_scalar('Validation/Avg_PSNR', avg_psnr, global_step=epoch)\n","    writer.add_scalar('Validation/Avg_SSIM', avg_ssim, global_step=epoch)\n","    writer.add_histogram('Generator/First_Layer_Weights', list(generator.parameters())[0], global_step=epoch)\n","    writer.add_scalar('Learning Rate/Generator', gen_optim.param_groups[0]['lr'], global_step=epoch)\n","    writer.add_scalar('Learning Rate/Discriminator', dis_optim.param_groups[0]['lr'], global_step=epoch)\n","    writer.flush()\n","\n","    # Reset for next epoch\n","    psnrs.clear()\n","    ssims.clear()\n","\n","    # Check for early stopping\n","    if epochs_no_improve >= patience:\n","        print(\"An early stopping here?!\")\n","        #break\n","\n","hparam_dict = {'lr': generator_lr, 'batch_size': batch_size}\n","metric_dict = {'best_psnr': best_psnr}\n","\n","writer.add_hparams(hparam_dict, metric_dict)\n","\n","writer.close()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}
