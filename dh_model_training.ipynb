{"cells":[{"cell_type":"markdown","metadata":{"id":"rUiPvRyhgbXt"},"source":["### Image To Image Translation Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GHpkMFd1uGFf"},"outputs":[],"source":["!pip install lpips\n","!pip install pytorch_msssim"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WrJhF-f_iqLb"},"outputs":[],"source":["import os\n","import time\n","import numpy as np\n","import pandas as pd\n","import cv2\n","import logging\n","import glob\n","import matplotlib.pyplot  as plt\n","\n","from lpips import LPIPS\n","\n","import torch\n","import torch.nn            as nn\n","import torch.nn.functional as F\n","\n","from torch.nn.utils           import clip_grad_norm_\n","from torch.utils.data         import Dataset, DataLoader, TensorDataset\n","from torch.utils.tensorboard  import SummaryWriter\n","from torch.optim              import Adam\n","from torch.optim.lr_scheduler import StepLR\n","from torch.cuda.amp import GradScaler\n","\n","from torchvision            import transforms\n","from torchvision.transforms import Grayscale\n","\n","from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n","\n","from PIL import Image\n","\n","from sklearn.model_selection import train_test_split\n","from skimage.morphology import disk\n","from math import log10\n","\n","logging.getLogger('lpips').setLevel(logging.WARNING)"]},{"cell_type":"markdown","metadata":{"id":"7jlwr5DkWWdc"},"source":["Project path in Google Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XLftWlQ5WWdh"},"outputs":[],"source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","PROJECT_PATH = '/content/drive/My Drive/Research Hub/Projects/Present Projects/{Deep Hadad}/Implementation/DeepHadadProject/'"]},{"cell_type":"markdown","metadata":{"id":"_GhGemFFWWdh"},"source":["Local Project path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mh4hnQo1WWdh"},"outputs":[],"source":["PROJECT_PATH = './'"]},{"cell_type":"markdown","metadata":{"id":"uzYgg8BBWWdh"},"source":["### Constants"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mxtAsVhGWWdi"},"outputs":[],"source":["TRAINING_DATASET_PATH   = PROJECT_PATH + 'data/small_training_dataset'\n","X_TRAINING_DATASET_PATH = TRAINING_DATASET_PATH + '/X'\n","Y_TRAINING_DATASET_PATH = TRAINING_DATASET_PATH + '/Y'\n","MODEL_PATH              = PROJECT_PATH + 'models/'\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","writer = SummaryWriter(PROJECT_PATH + '/runs/experiment_1')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BTW6k6XPuvRC"},"outputs":[],"source":["import sys\n","sys.path.append(PROJECT_PATH)\n","\n","import core.networks as dh_networks"]},{"cell_type":"markdown","metadata":{"id":"Bm-LULpeJOEG"},"source":["### Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tyGCgjU8JO1L"},"outputs":[],"source":["generator_lr        = 5e-5     # Reduced learning rate for generator\n","discriminator_lr    = 5e-5     # Unchanged learning rate for discriminator\n","batch_size          = 26       # Batch size\n","num_epochs          = 100      # Number of epochs\n","checkpoint_interval = 10       # Interval between saving model checkpoints"]},{"cell_type":"markdown","metadata":{"id":"37q6KY6IV88y"},"source":["### Dataset Loading"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CrlOJ6v8V7fV"},"outputs":[],"source":["IMAGE_EXTENSIONS = [\".png\", \".jpg\", \".jpeg\", \".tif'\", \".tiff\", \".bmp\"]\n","\n","def get_image_paths(directory):\n","    image_paths = []\n","    for ext in IMAGE_EXTENSIONS:\n","        image_paths.extend(glob.glob(os.path.join(directory, '*' + ext)))\n","    return sorted(image_paths)\n","\n","# Get images from path\n","intact_image_paths    = get_image_paths(X_TRAINING_DATASET_PATH)\n","damaged_image_paths = get_image_paths(Y_TRAINING_DATASET_PATH)\n","\n","print(f\"Number of Paired Inscriptions: {len(intact_image_paths)}\")\n","print(f\"Number of Paired Inscriptions: {len(damaged_image_paths)}\")\n","\n","assert len(intact_image_paths) == len(damaged_image_paths), \"Number of intact and damaged images must be the same\"\n","\n","print(f\"Number of Paired Inscriptions: {len(intact_image_paths)}\")\n","\n","class DisplacementMapDataset(Dataset):\n","  def __init__(self, intact_image_paths, damaged_image_paths, transform=None):\n","    self.intact_image_paths  = intact_image_paths\n","    self.damaged_image_paths = damaged_image_paths\n","    self.transform           = transform\n","    self.counter             = 0\n","\n","  def __len__(self):\n","    return len(self.intact_image_paths)\n","\n","  def __getitem__(self, idx):\n","    while True:\n","      try:\n","        intact_image_path  = self.intact_image_paths[idx]\n","        damaged_image_path = self.damaged_image_paths[idx]\n","\n","        intact_image  = Image.open(intact_image_path)\n","        damaged_image = Image.open(damaged_image_path)\n","\n","        if self.transform:\n","          intact_image  = self.transform(intact_image)\n","          damaged_image = self.transform(damaged_image)\n","\n","        # Increment the counter and log every 100 pairs\n","        self.counter += 1\n","\n","        if self.counter % 100 == 0:\n","          print(f\"Processed {self.counter} pairs. Current pair: {intact_image_path}, {damaged_image_path}\")\n","\n","        return intact_image, damaged_image\n","      except IOError as e:\n","        print(f\"Error opening image files: {intact_image_path}, {damaged_image_path}. Error: {e}\")\n","        # Increment the index and try the next pair of images\n","        idx = (idx + 1) % len(self.intact_image_paths)\n","\n","# Common Data Augmentation\n","common_transforms = transforms.Compose([\n","  transforms.Resize((512, 512)),\n","  transforms.Lambda(lambda x: x.convert('L')),\n","  transforms.ToTensor()\n","])\n","\n","\n","# Calculate mean and std for the dataset\n","mean = 0.\n","std = 0.\n","\n","# Use a subset to calculate mean and std for efficiency\n","subset_intact_image_paths = intact_image_paths[:100]\n","subset_damaged_image_paths = damaged_image_paths[:100]\n","\n","for images, _ in DataLoader(DisplacementMapDataset(subset_intact_image_paths, subset_damaged_image_paths, transform=common_transforms), batch_size=batch_size):\n","    images       = images.to(device)  # Move images to GPU\n","    batch_samples = len(images)  # Use len() to get the number of images in the batch\n","    images       = images.view(batch_samples, images.size(1), -1)\n","    mean      += images.mean(2).sum(0)\n","    std        += images.std(2).sum(0)\n","\n","mean /= len(intact_image_paths)\n","std   /= len(intact_image_paths)\n","\n","# Now mean and std should be tensors of size 1\n","print(mean.size())  # Should print torch.Size([1])\n","print(std.size())  # Should print torch.Size([1])\n","\n","# Data Augmentation for the Real Images\n","image_transforms = transforms.Compose([\n","    transforms.RandomResizedCrop(512, scale=(0.8, 1.0)),\n","    transforms.RandomRotation(10),\n","    #transforms.RandomCrop(224),\n","    common_transforms,\n","    transforms.Normalize(mean=mean.tolist(), std=std.tolist())  # Scale pixels to the range [-1, 1]\n","])\n","\n","# Split the data into training and validation sets\n","train_intact, val_intact, train_damaged, val_damaged = train_test_split(\n","    intact_image_paths, damaged_image_paths, test_size=0.2, random_state=42)\n","\n","# Create training and validation datasets and dataloaders\n","train_dataset = DisplacementMapDataset(train_intact, train_damaged, transform = image_transforms)\n","val_dataset   = DisplacementMapDataset(val_intact, val_damaged, transform = image_transforms)\n","\n","# Create dataset and dataloader\n","train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n","val_dataloader   = DataLoader(val_dataset, batch_size = batch_size, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"6gVYSuc_C43V"},"source":["### MODEL INITIALIZATION"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"80xJHGQoC3Ds"},"outputs":[],"source":["gen_in_channels  = 1  # grayscale images, 3 for RGB images\n","gen_out_channels = 1  # to generate grayscale restored images, change as needed\n","\n","# Instantiate the generator with the specified channel configurations\n","generator = dh_networks.DHadadGenerator(gen_in_channels, gen_out_channels).to(device)\n","\n","# Specify the input channel configurations (for the discriminator, it typically takes two inputs)\n","# Assuming you're providing pairs of images (intact and restored) as input\n","# and not input channels set to 3 (concatenation of real and synthetic images plus condition)\n","disc_in_channels = 1\n","\n","discriminator = dh_networks.DHadadDiscriminator(disc_in_channels).to(device)"]},{"cell_type":"markdown","metadata":{"id":"PAp0jCJVnQye"},"source":["### Initialize loss functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yJyTNQoxna3W"},"outputs":[],"source":["########################################################################################\n","# Mean Squared Error(MSE) Loss\n","# It ensures the overall structure of the reconstructed image\n","# is similar to the intact image.\n","# MSE could encourage blurred details, which can be detrimental for text recovery and for sharp engravings.\n","########################################################################################\n","mean_sq_error_loss = nn.MSELoss().to(device)\n","\n","########################################################################################\n","# L1 Loss\n","# It helps in recovering finer details without overly penalizing slight deviations that aren't perceptually significant.\n","########################################################################################\n","l1_loss = nn.L1Loss().to(device)\n","\n","########################################################################################\n","# Perceptual Loss\n","# Captures textural and stylistic features.\n","# luminance, and contrast in an image.\n","# A higher weight is crucial as it emphasizes on the perceptual similarity, which is key for letter reconstruction.\n","########################################################################################\n","class WeightedSSIMLoss(nn.Module):\n","    def __init__(self, data_range=255, size_average=True, channel=1, weight=1.0):\n","        super(WeightedSSIMLoss, self).__init__()\n","        self.ssim = SSIM(data_range=data_range, size_average=size_average, channel=channel)\n","        self.weight = weight\n","\n","    def forward(self, img1, img2):\n","        ssim_loss = self.ssim(img1, img2)\n","        weighted_ssim_loss = self.weight * (1 - ssim_loss)  # Weighted SSIM loss\n","\n","        return weighted_ssim_loss\n","\n","weighted_ssim_loss = WeightedSSIMLoss(data_range=255, size_average=True, channel=1, weight=1.0)\n","\n","########################################################################################\n","# LPIPS Loss\n","# LPIPS is a perceptual loss that uses a pretrained VGG19 network to calculate\n","########################################################################################\n","lpips_loss = LPIPS(net='vgg').to(device)  # Use the AlexNet layer\n","\n","########################################################################################\n","# Adversarial Loss\n","# TO encourage the generator to create images that are indistinguishable\n","# from the intact displacement maps.\n","# Encourages realism in the generated maps.\n","# Keeping this weight lower ensures that the focus remains on structural and textural accuracy rather than just realism.\n","########################################################################################\n","bce_with_logits_loss = nn.BCEWithLogitsLoss().to(device)\n","\n","def adversarial_loss(discriminator_preds, is_real=True):\n","    if is_real:\n","        labels = torch.ones_like(discriminator_preds).to(device)\n","    else:\n","        labels = torch.zeros_like(discriminator_preds).to(device)\n","\n","    return bce_with_logits_loss(discriminator_preds, labels)\n","\n","########################################################################################\n","# DepthConsistencyLoss\n","# This is a robust loss that combines the benefits of L1 and L2 losses.\n","# It can be particularly useful if there's a lot of noise in the damaged maps.\n","# Depth data is uncertain in some places\n","# This loss can help in smoothing the depth map without losing essential details.\n","########################################################################################\n","class DepthConsistencyLoss(nn.Module):\n","    def __init__(self, epsilon=1e-6):\n","        super(DepthConsistencyLoss, self).__init__()\n","        self.epsilon = epsilon\n","\n","    def forward(self, generated_depth, target_depth):\n","        # Assuming generated_depth and target_depth are tensors representing depth maps\n","        # Charbonnier Loss: sqrt((x - y)^2 + epsilon)\n","        loss = torch.mean(torch.sqrt((generated_depth - target_depth) ** 2 + self.epsilon))\n","        return loss\n","\n","depth_consistency_loss = DepthConsistencyLoss().to(device)\n","\n","########################################################################################\n","# Geometric Consistency Loss\n","# Maintains geometric integrity of depth information.\n","# This will help in preserving the contours and shapes of letters in the displacement maps.\n","########################################################################################\n","class GeometricConsistencyLoss(nn.Module):\n","    def __init__(self):\n","        super(GeometricConsistencyLoss, self).__init__()\n","\n","    def forward(self, predicted_map, target_map):\n","        # Calculate gradients in x and y direction\n","        # These gradients represent the change in depth (or displacement) across pixels\n","        grad_x_pred, grad_y_pred = self.compute_gradients(predicted_map)\n","        grad_x_target, grad_y_target = self.compute_gradients(target_map)\n","\n","        # Calculate the loss as the mean squared error between the gradients of the predicted and target maps\n","        loss_x = F.mse_loss(grad_x_pred, grad_x_target)\n","        loss_y = F.mse_loss(grad_y_pred, grad_y_target)\n","\n","        # Combine the losses\n","        loss = loss_x + loss_y\n","\n","        return loss\n","\n","    def compute_gradients(self, map):\n","        # Function to compute gradients in the x and y direction\n","        grad_x = map[:, :, :, :-1] - map[:, :, :, 1:]\n","        grad_y = map[:, :, :-1, :] - map[:, :, 1:, :]\n","\n","        return grad_x, grad_y\n","\n","# Example usage\n","geometric_consistency_loss = GeometricConsistencyLoss().to(device)\n","\n","\n","def tv_loss(img):\n","    batch_size, _, height, width = img.size()\n","    tv_h = torch.pow(img[:, :, 1:, :] - img[:, :, :-1, :], 2).sum()\n","    tv_w = torch.pow(img[:, :, :, 1:] - img[:, :, :, :-1], 2).sum()\n","\n","    return (tv_h + tv_w) / (batch_size * height * width)\n","\n","########################################################################################\n","# Dynamic Loss Weights\n","########################################################################################\n","class DynamicLossWeights:\n","    def __init__(self, initial_weights, max_weight=1.0, min_weight=0.01, decay_factor=0.9):\n","        self.weights = initial_weights\n","        self.max_weight = max_weight\n","        self.min_weight = min_weight\n","        self.decay_factor = decay_factor\n","\n","    def update_weights(self, performance_metrics):\n","        # Adjust weights based on the specific metric and its improvement\n","        for metric, info in performance_metrics.items():\n","            improvement = info['improved']\n","            magnitude = info['magnitude']\n","\n","            if metric == 'esi':\n","                # ESI is a measure of edge similarity.\n","                # Higher ESI indicates better structural integrity.\n","                self.adjust_weight_for_metric('zeta', improvement, magnitude) # Geometric Consistency Loss adjustment\n","\n","                # Adversarial loss might be tuned down if ESI is high, focusing more on realism\n","                self.adjust_weight_for_metric('delta', improvement, magnitude) # Adversarial Loss adjustment\n","\n","            if metric == 'psnr':\n","                # PSNR focuses on reconstruction quality.\n","                # Improvement in PSNR indicates better structural integrity.\n","                self.adjust_weight_for_metric('alpha', improvement, magnitude) # MSE Loss adjustment\n","\n","                # Improvement in PSNR indicates better structural integrity.\n","                self.adjust_weight_for_metric('beta', improvement, magnitude) # L1 Loss adjustment\n","\n","            if metric == 'ssim':\n","                # SSIM focuses on perceptual similarity.\n","                # Improvement in SSIM indicates better structural integrity.\n","                self.adjust_weight_for_metric('gamma', improvement, magnitude) # SSIM Loss adjustment\n","\n","        self.normalize_weights()\n","\n","        return self.weights\n","\n","    def adjust_weight_for_metric(self, weight_key, improvement, magnitude):\n","        factor = self.decay_factor if improvement else 1.1 * (1 + magnitude)\n","\n","        self.weights[weight_key] *= factor\n","\n","        self.weights[weight_key] = min(max(self.weights[weight_key], self.min_weight), self.max_weight)\n","\n","    def normalize_weights(self):\n","        total_weight = sum(self.weights.values())\n","        for key in self.weights:\n","            self.weights[key] = (self.weights[key] / total_weight) * self.max_weight\n","\n","\n","    def clamp_weight(self, weight):\n","        return max(min(weight, self.max_weight), self.min_weight)\n","\n","########################################################################################\n","# Initial Loss Weights\n","#\n","# Adjusting the loss weights for DeepHadad's displacement map inscription restoration\n","########################################################################################\n","\n","initial_weights = {\n","    'alpha':   0.1,   # Weight for MSE Loss\n","    'beta':    0.55,   # Weight for Reconstruction Loss (L1)\n","    'gamma':   0.4,   # Weight for SSIM in Perceptual Loss\n","    'delta':   0.1,   # Weight for Adversarial Loss\n","    'epsilon': 0.2,   # Weight for Depth Consistency Loss\n","    'zeta':    0.25,   # Weight for Geometric Consistency Loss\n","    'eta':     0.01   # Weight for TV Loss\n","}\n","\n","loss_weights    = DynamicLossWeights(initial_weights)\n","\n","########################################################################################\n","# Combined generator loss function.\n","########################################################################################\n","def combined_gen_loss(gen_imgs, real_imgs, discriminator_preds, loss_weights):\n","    # Mean Squared Error Loss\n","    mse_loss = mean_sq_error_loss(gen_imgs, real_imgs)\n","\n","    # Reconstruction Loss (L1)\n","    recon_loss = l1_loss(gen_imgs, real_imgs)\n","\n","    # Perceptual Loss\n","    ssim_loss = weighted_ssim_loss(gen_imgs, real_imgs).to(device)\n","    #lpips_loss_value = lpips_loss(gen_imgs, real_imgs)\n","\n","    # Adversarial Loss for the generator\n","    adv_loss = adversarial_loss(discriminator_preds, is_real=False)\n","\n","    # Charbonnier Loss (robust L1/L2 loss)\n","    depth_loss = depth_consistency_loss(gen_imgs, real_imgs)\n","\n","    # predicted_map and target_map are your generated and ground truth displacement maps, respectively\n","    geom_loss = geometric_consistency_loss(gen_imgs, real_imgs)\n","\n","    #TV loss function\n","    tv_loss_value = tv_loss(gen_imgs)\n","\n","\n","    combined_loss = torch.mean(\n","        loss_weights['alpha'] * mse_loss + \\\n","        loss_weights['beta'] * recon_loss + \\\n","        loss_weights['gamma'] * ssim_loss + \\\n","        loss_weights['delta']* adv_loss + \\\n","        loss_weights['epsilon'] * depth_loss + \\\n","        loss_weights['zeta'] * geom_loss + \\\n","        loss_weights['eta'] * tv_loss_value\n","    )\n","\n","    return combined_loss"]},{"cell_type":"markdown","metadata":{"id":"c0498ro7es0F"},"source":["### Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NiFoN2HbeqS0"},"outputs":[],"source":["# Define the maximum gradient norm for clipping\n","max_grad_norm = 1.0\n","\n","# Initialize optimizers\n","gen_optim = Adam(generator.parameters(), lr=generator_lr, betas=(0.5, 0.999))\n","dis_optim = Adam(discriminator.parameters(), lr=discriminator_lr, betas=(0.5, 0.999))\n","\n","#Learning Rate Scheduling\n","gen_scheduler = StepLR(gen_optim, step_size=30, gamma=0.1)\n","dis_scheduler = StepLR(dis_optim, step_size=30, gamma=0.1)\n","\n","# ----------------------------------------------------\n","# Define Evaluation Functions\n","# -------------------------------------------------\n","def compute_psnr(img1, img2):\n","    mse = F.mse_loss(img1, img2)\n","\n","    if mse == 0:\n","        return float('inf')\n","\n","    # Add a small positive number inside the square root to ensure the input is always non-negative\n","    return 20 * log10(1.0 / torch.sqrt(mse + 1e-10))\n","\n","def ssim(img1, img2, C1=0.01**2, C2=0.03**2):\n","    mu1 = torch.mean(img1, dim=[1, 2, 3])\n","    mu2 = torch.mean(img2, dim=[1, 2, 3])\n","\n","    sigma1_sq = torch.mean((img1 - mu1.reshape(-1, 1, 1, 1)) ** 2, dim=[1, 2, 3])\n","    sigma2_sq = torch.mean((img2 - mu2.reshape(-1, 1, 1, 1)) ** 2, dim=[1, 2, 3])\n","    sigma12   = torch.mean((img1 - mu1.reshape(-1, 1, 1, 1)) * (img2 - mu2.reshape(-1, 1, 1, 1)), dim=[1, 2, 3])\n","\n","    SSIM_n = (2 * mu1 * mu2 + C1) * (2 * sigma12 + C2)\n","    SSIM_d = (mu1 * mu1 + mu2 * mu2 + C1) * (sigma1_sq + sigma2_sq + C2)\n","    SSIM   = SSIM_n / SSIM_d\n","\n","    return torch.mean(SSIM)  # Return the mean SSIM over the batch\n","\n","########################################################################################\n","# Edge Similarity Index (ESI)\n","########################################################################################\n","def compute_edge_similarity(img1, img2, device=device):\n","    # Ensure the images are single-channel and convert to NumPy arrays if they are tensors\n","    if torch.is_tensor(img1):\n","        img1 = img1.squeeze().cpu().numpy()\n","    if torch.is_tensor(img2):\n","        img2 = img2.squeeze().cpu().numpy()\n","\n","    # Calculate Sobel edges for image 1\n","    sobelx = cv2.Sobel(img1, cv2.CV_64F, dx=1, dy=0, ksize=5)\n","    sobely = cv2.Sobel(img1, cv2.CV_64F, dx=0, dy=1, ksize=5)\n","    edge1 = cv2.magnitude(sobelx, sobely)\n","\n","    # Calculate Sobel edges for image 2\n","    sobelx = cv2.Sobel(img2, cv2.CV_64F, 1, 0, ksize=5)\n","    sobely = cv2.Sobel(img2, cv2.CV_64F, 0, 1, ksize=5)\n","    edge2 = cv2.magnitude(sobelx, sobely)\n","\n","    # Convert edges back to PyTorch tensors for SSIM calculation\n","    edge1_tensor = torch.tensor(edge1, dtype=torch.float32).unsqueeze(0).to(device)\n","    edge2_tensor = torch.tensor(edge2, dtype=torch.float32).unsqueeze(0).to(device)\n","\n","    return ssim(edge1_tensor, edge2_tensor)\n","\n","########################################################################################\n","# Combined Score\n","# A combined score that takes into account PSNR, SSIM, and ESI\n","########################################################################################\n","def combined_score(psnr, ssim, edge_similarity, weights = [0.4, 0.3, 0.3]):\n","    weighted_psnr = 0.4 * psnr\n","    weighted_ssim = 0.3 * ssim\n","    weighted_edge = 0.3 * edge_similarity\n","\n","    total_score = weighted_psnr + weighted_ssim + weighted_edge\n","\n","    return total_score\n","\n","# ----------------------------------------------------\n","# Define Evaluation Functions\n","# Gradient Penalty\n","# The gradient penalty is typically used in the context of Wasserstein GANs\n","# with Gradient Penalty (WGAN-GP).\n","# It enforces the Lipschitz constraint by penalizing the gradient norm\n","# of the discriminator's output with respect to its input.\n","# -------------------------------------------------\n","def compute_gradient_penalty(D, real_samples, fake_samples):\n","    # Random weight term for interpolation between real and fake samples\n","    alpha = torch.rand((real_samples.size(0), 1, 1, 1), device=real_samples.device)\n","    # Get random interpolation between real and fake samples\n","    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n","    d_interpolates = D(interpolates)\n","    fake = torch.ones(d_interpolates.size(), requires_grad=False, device=real_samples.device)\n","\n","    # Get gradient w.r.t. interpolates\n","    gradients = torch.autograd.grad(\n","        outputs=d_interpolates,\n","        inputs=interpolates,\n","        grad_outputs=fake,\n","        create_graph=True,\n","        retain_graph=True,\n","        only_inputs=True,\n","    )[0]\n","\n","    gradients = gradients.view(gradients.size(0), -1)\n","    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n","    return gradient_penalty\n","\n","\n","# Initialize some variables for averaging\n","best_psnr = -float('inf')\n","best_ssim = -float('inf')\n","best_esi    = -float('inf')\n","best_combined_score = -float('inf')\n","patience = 10  # Number of epochs to wait for improvement\n","epochs_no_improve = 0  # Counter for epochs without improvement\n","avg_psnr = 0.0\n","avg_ssim = 0.0\n","avg_esi  = 0.0\n","num_batches = 0\n","min_psnr, max_psnr = float('inf'), float('-inf')\n","min_ssim, max_ssim = float('inf'), float('-inf')\n","min_esi,  max_esi  = float('inf'), float('-inf')\n","std_psnr, std_ssim, std_esi = 0, 0, 0  # Standard deviation\n","gen_loss, dis_loss = 0, 0  # Generator and Discriminator losse\n","psnrs, ssims, esis = [], [], [] # Lists to store all PSNR and SSIM values for each epoch\n","epoch_times = []  # List to store time taken for each epoch\n","lambda_gp = 10  # The gradient penalty coefficient\n","\n","# Set the number of critic updates per generator update\n","critic_updates_per_gen_update = 3\n","\n","torch.autograd.set_detect_anomaly(True)\n","\n","# Initialize GradScaler\n","#scaler = GradScaler()\n","\n","# ----------------------------------------------------\n","# TRAINING LOOP\n","# ---------------------------------------------------\n","for epoch in range(num_epochs):\n","    # Start time for this epoch\n","    start_time = time.time()\n","    epoch_metrics = {'psnr': {'total': 0, 'count': 0}, 'ssim': {'total': 0, 'count': 0}, 'esi': {'total': 0, 'count': 0}}\n","\n","    for i, (damaged, intact) in enumerate(train_dataloader): # (intact, damaged) correct\n","        intact, damaged = intact.to(device), damaged.to(device)\n","\n","        if epoch == 0 and i == 0:\n","            writer.add_graph(generator, damaged)\n","\n","        # Generate restored images from the damaged images\n","        restored = generator(damaged)\n","\n","        # ---------------------------------------------------\n","        # Update Discriminator\n","        # ---------------------------------------------------\n","        for _ in range(critic_updates_per_gen_update):\n","            dis_optim.zero_grad()\n","\n","            # Classify real and fake images\n","            output_real = discriminator(intact)\n","            output_fake = discriminator(restored.detach())\n","\n","            real_loss = adversarial_loss(output_real, is_real=True)\n","            fake_loss = adversarial_loss(output_fake, is_real=False)\n","\n","            # Compute gradient penalty\n","            gradient_penalty = compute_gradient_penalty(discriminator, intact, restored.detach())\n","\n","            # Compute the total discriminator loss\n","            dis_loss = 0.5 * (real_loss + fake_loss) + lambda_gp * gradient_penalty\n","\n","            # Scale the loss\n","            dis_loss.backward()\n","\n","            # Clip gradients for discriminator\n","            clip_grad_norm_(discriminator.parameters(), max_norm=max_grad_norm)\n","\n","            # Optimize\n","            dis_optim.step()\n","\n","        # ---------------------------------------------------\n","        # Update Generator\n","        # ---------------------------------------------------\n","        # Reset gradients\n","        gen_optim.zero_grad()\n","\n","        output_fake_for_gen = discriminator(restored)\n","        gen_loss           = combined_gen_loss(restored, intact, output_fake_for_gen, loss_weights.weights)\n","\n","        # Scale the loss\n","        gen_loss.backward()\n","\n","        # Clip gradients for generator\n","        clip_grad_norm_(generator.parameters(), max_norm=max_grad_norm)\n","\n","        # Optimize\n","        gen_optim.step()\n","\n","        writer.add_scalar('Generator Loss',     gen_loss, global_step=epoch * len(train_dataloader) + i)\n","        writer.add_scalar('Discriminator Loss', dis_loss, global_step=epoch * len(train_dataloader) + i)\n","\n","    # ---------------------------------------------------\n","    # Validation step\n","    # ---------------------------------------------------\n","    with torch.no_grad():\n","          # Clip val gradients\n","        torch.nn.utils.clip_grad_norm_(generator.parameters(), max_norm=1.0)\n","\n","        for damaged, intact in val_dataloader: # intact, damaged c\n","            intact  = intact.to(device)\n","            damaged = damaged.to(device)\n","\n","            # Generate restored images\n","            restored = generator(damaged)\n","\n","            # Clamp the values to be between 0 and 1\n","            restored = restored.clamp(0, 1)\n","            intact = intact.clamp(0, 1)\n","\n","            writer.add_images('Restored Images', restored, global_step=epoch)\n","\n","            # Compute PSNR and SSIM for the current batch\n","            batch_psnr = compute_psnr(restored, intact)\n","            batch_ssim = ssim(restored, intact)\n","            batch_edge_similarity = compute_edge_similarity(restored, intact)\n","\n","            psnrs.append(batch_psnr)\n","            ssims.append(batch_ssim)\n","            esis.append(batch_edge_similarity)\n","\n","            # Update epoch metrics\n","            epoch_metrics['psnr']['total'] += batch_psnr\n","            epoch_metrics['psnr']['count'] += 1\n","            epoch_metrics['ssim']['total'] += batch_ssim\n","            epoch_metrics['ssim']['count'] += 1\n","            epoch_metrics['esi']['total']  += batch_edge_similarity\n","            epoch_metrics['esi']['count']  += 1\n","\n","    # Switch back to training mode\n","    generator.train()\n","    discriminator.train()\n","\n","    # Move tensors to CPU and convert to float\n","    psnrs_cpu = [x.cpu().item() if torch.is_tensor(x) else x for x in psnrs]\n","    ssims_cpu = [x.cpu().item() if torch.is_tensor(x) else x for x in ssims]\n","    esis_cpu  = [x.cpu().item() if torch.is_tensor(x) else x for x in esis]\n","\n","    avg_psnr = np.mean(psnrs_cpu)\n","    avg_ssim = np.mean(ssims_cpu)\n","    avg_esi  = np.mean(esis_cpu)\n","\n","    # At the end of the epoch, calculate average metrics\n","    avg_psnr_epoch = epoch_metrics['psnr']['total'] / epoch_metrics['psnr']['count']\n","    avg_ssim_epoch = epoch_metrics['ssim']['total'] / epoch_metrics['ssim']['count']\n","    avg_esi_epoch  = epoch_metrics['esi']['total']  / epoch_metrics['esi']['count']\n","\n","    # Calculate combined score for the epoch\n","    epoch_combined_score = combined_score(avg_psnr_epoch, avg_ssim_epoch, avg_esi_epoch)\n","\n","    # Save model checkpoints at regular intervals and best models\n","    if epoch % checkpoint_interval == 0 or avg_psnr_epoch > best_psnr or avg_ssim_epoch > best_ssim or avg_esi_epoch > best_esi:\n","        MODEL_NAME = f\"generator_model_epoch_{epoch}.pth\"\n","\n","        torch.save(generator.state_dict(), os.path.join(MODEL_PATH, MODEL_NAME))\n","\n","    # Early stopping based on combined score\n","    if epoch_combined_score > best_combined_score:\n","        best_combined_score = epoch_combined_score\n","        epochs_no_improve = 0\n","    else:\n","        epochs_no_improve += 1\n","\n","    if epochs_no_improve >= patience:\n","        print(f\"Early stopping at epoch {epoch} due to no improvement.\")\n","        #break\n","\n","    # Update loss weights based on performance\n","    performance_metrics = {\n","        'psnr': {'improved': avg_psnr > best_psnr, 'magnitude': abs(avg_psnr_epoch - best_psnr)},\n","        'ssim': {'improved': avg_ssim > best_ssim, 'magnitude': abs(avg_ssim_epoch - best_ssim)},\n","        'esi':  {'improved': avg_esi > best_esi, 'magnitude': abs(avg_esi_epoch - best_esi)}\n","    }\n","\n","    # Calculate min and max values\n","    min_psnr, max_psnr = np.min(psnrs_cpu), np.max(psnrs_cpu)\n","    min_ssim, max_ssim = np.min(ssims_cpu), np.max(ssims_cpu)\n","    min_esi,  max_esi  = np.min(esis_cpu),  np.max(esis_cpu)\n","\n","    # Calculate standard deviation\n","    std_psnr, std_ssim, std_esi = np.std(psnrs_cpu), np.std(psnrs_cpu), np.std(esis_cpu)\n","\n","    # Calculate time taken for this epoch\n","    epoch_time = time.time() - start_time\n","\n","    # Store for future analysis if needed\n","    epoch_times.append(epoch_time)\n","\n","    # Logging\n","    print(f\" Epoch {epoch+1}/{num_epochs} - Time: {epoch_time:.2f}s\")\n","    print(f\" Loss Weights:   {loss_weights.weights}\")\n","    print(f\" Average PSNR:   {avg_psnr:.4f} (Min: {min_psnr:.4f}, Max: {max_psnr:.4f}, Std: {std_psnr:.4f}, Epoch Avg: {avg_psnr_epoch:.4f})\")\n","    print(f\" Average SSIM:   {avg_ssim:.4f} (Min: {min_ssim:.4f}, Max: {max_ssim:.4f}, Std: {std_ssim:.4f}, Epoch Avg: {avg_ssim_epoch:.4f})\")\n","    print(f\" Average ESI:    {avg_esi:.4f}  (Min: {min_esi:.4f},  Max: {max_esi:.4f},  Std: {std_esi:.4f},  Epoch Avg: {avg_esi_epoch:.4f})\")\n","    print(f\" Combined Score: {combined_score(avg_psnr, avg_ssim, avg_esi):.4f}\")\n","    print(f\" Generator Loss: {gen_loss:.4f}, Discriminator Loss: {dis_loss:.4f}\")\n","\n","    writer.add_scalar('Validation/Avg_PSNR', avg_psnr, global_step=epoch)\n","    writer.add_scalar('Validation/Avg_SSIM', avg_ssim, global_step=epoch)\n","    writer.add_histogram('Generator/First_Layer_Weights', list(generator.parameters())[0], global_step=epoch)\n","    writer.add_scalar('Learning Rate/Generator', gen_optim.param_groups[0]['lr'], global_step=epoch)\n","    writer.add_scalar('Learning Rate/Discriminator', dis_optim.param_groups[0]['lr'], global_step=epoch)\n","    writer.flush()\n","\n","    # Reset for next epoch\n","    psnrs.clear()\n","    ssims.clear()\n","    esis.clear()\n","\n","    loss_weights.update_weights(performance_metrics)\n","\n","    # Normalize weights every N epochs\n","    if epoch % 5 == 0:\n","      loss_weights.normalize_weights()\n","\n","    # Step the learning rate scheduler\n","    gen_scheduler.step()\n","    dis_scheduler.step()\n","\n","hparam_dict = {'lr': generator_lr, 'batch_size': batch_size}\n","metric_dict = {'best_psnr': best_psnr}\n","\n","writer.add_hparams(hparam_dict, metric_dict)\n","\n","writer.close()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}
